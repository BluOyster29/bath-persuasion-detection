{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd69d66-261a-446b-9f8e-5b6023f7e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406e8c6-e45a-48ca-bff3-03a6b8a0efc4",
   "metadata": {},
   "source": [
    "# Gen Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a62a74-cab5-490c-ae43-6fe22984794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_df = pd.read_csv('../data/binary_classifier/binary_label_1-RAPPORT.csv')\n",
    "label = 'Rapport'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49533c0f-b187-485f-823f-290a192bc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer \n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "\n",
    "def gen_sampler(dataset):\n",
    "    \n",
    "    class_counts = dataset.data.binary_label.value_counts().to_list()\n",
    "    num_samples = sum(class_counts)\n",
    "    labels = dataset.data.binary_label.tolist()\n",
    "    class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "    weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "    sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "    return sampler\n",
    "    \n",
    "class binaryPersuasionDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, data, label, tokenizer\n",
    "            ):\n",
    "        \n",
    "        self.data = data.sample(frac=1)\n",
    "        self.label = label\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n",
    "        self.max_token_len = 512\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        data_row = self.data.iloc[index]\n",
    "        comment_text = data_row.text\n",
    "        binary_label = data_row.binary_label\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          comment_text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_token_len,\n",
    "          return_token_type_ids=False,\n",
    "          padding=\"max_length\",\n",
    "          truncation=True,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "          comment_text=comment_text[:10],\n",
    "          input_ids=encoding[\"input_ids\"].flatten(),\n",
    "          attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "          binary_label=torch.FloatTensor([binary_label])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c50694c-74d7-4695-8673-50a12dec8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_datasets(df, label, tokenizer):\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        df,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    train_ds = binaryPersuasionDataset(\n",
    "        bin_df,\n",
    "        label,\n",
    "        tokenizer\n",
    "    )\n",
    "\n",
    "    test_ds = binaryPersuasionDataset(\n",
    "        test_df,\n",
    "        label,\n",
    "        tokenizer)\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ec907e3-523b-44ed-b465-cdaf59c64e26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_dataloaders(dataset, batch_size, test=None):\n",
    "\n",
    "    if test:\n",
    "        sampler=None\n",
    "    else:\n",
    "        sampler = weighted_sampler = gen_sampler(ds)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        sampler=sampler,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c7750c9-8bc9-48e6-a82d-c9f50f764bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = gen_datasets(bin_df, 'rapport', 'bert-base-uncased')\n",
    "train_dataloader = gen_dataloaders(train_dataset, 4)\n",
    "test_dataloader = gen_dataloaders(test_dataset, 1, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b62749d-fd39-403b-ab02-6ee34f4bbdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    BERT-based classifier model.\n",
    "\n",
    "    Args:\n",
    "        bert_model (str): The pre-trained BERT model to use.\n",
    "        num_labels (int): The number of output labels.\n",
    "\n",
    "    Attributes:\n",
    "        bert (BertModel): The BERT model.\n",
    "        dropout (nn.Dropout): Dropout layer for regularization.\n",
    "        classifier (nn.Linear): Linear layer for classification.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, bert_model, num_labels):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.name = name\n",
    "        self.bert = AutoModel.from_pretrained(bert_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass of the BERT classifier.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): The input token IDs.\n",
    "            attention_mask (torch.Tensor): The attention mask.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The logits for each class.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.name == 'bert':\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "            pooled_output = outputs.pooler_output\n",
    "\n",
    "        elif self.name == 'distilbert':\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "            pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model name\")\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ffb11-1f26-4c78-a592-f73a09dc524b",
   "metadata": {},
   "source": [
    "# Set Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d2c6864-e9c6-403c-a00d-e4d9032bf784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from transformers import AutoModel\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "num_epochs = 15\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss for multilabel classification\n",
    "\n",
    "model = BertClassifier('distilbert', 'bert-base-uncased', 2)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439efc4f-aab5-4fd5-a02d-dca8058ffc1d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ca24d85e-b87c-440c-9a1b-eb8d65d2e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(\n",
    "        model, training_dataloader, num_epochs, device, optimizer, criterion):\n",
    "\n",
    "    avg_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(range(num_epochs), desc='Average Epoch Loss: ') as t:\n",
    "        for e in range(num_epochs):\n",
    "            epoch_loss = []\n",
    "\n",
    "            with tqdm(range(len(training_dataloader)), desc='Loss: 0') as t2:\n",
    "                for b, batch in enumerate(training_dataloader):\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if model.name == 'rnn':\n",
    "                        input_ids = batch['input_ids'].to(device)\n",
    "                        labels = batch['binary_label'].to(device)\n",
    "                        embeddings = model.embd(input_ids)\n",
    "                        outputs = model(embeddings)\n",
    "\n",
    "                    elif model.name in ['bert', 'distilbert']:\n",
    "                        input_ids = batch['input_ids'].to(device)\n",
    "                        attention_mask = batch['attention_mask'].to(device)\n",
    "                        labels = batch['binary_label'].to(device)\n",
    "                        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "                    labels = one_hot_encode(labels)\n",
    "                    loss = criterion(outputs, labels.float())\n",
    "                    epoch_loss.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    avg_epoch_loss = round(sum(epoch_loss)/len(epoch_loss), 4)\n",
    "                    description = f'Epoch: {e} | '\n",
    "                    description += f'Batch {b} | '\n",
    "                    description += f'Average Loss: {avg_epoch_loss}'\n",
    "\n",
    "                    t2.set_description(description)\n",
    "                    t2.update()\n",
    "\n",
    "            t.set_description(\n",
    "                f'Average Epoch Loss: {round(sum(epoch_loss)/len(epoch_loss),4)}')\n",
    "            t.update()\n",
    "\n",
    "    return avg_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "59e76d13-8886-4f6a-9b71-4f132c08e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model, o = train_model(model, train_dataloader, num_epochs, device, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63fd704c-53d3-457e-86f0-21c664788ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, eval_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model on the evaluation data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        eval_loader (torch.utils.data.DataLoader): The data loader for\n",
    "        the evaluation data.\n",
    "        device (torch.device): The device to run the evaluation on.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the true labels and predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "\n",
    "            if model.name == 'rnn':\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                labels = batch['binary_label'].to(device)\n",
    "                embeddings = model.embd(input_ids)\n",
    "                outputs = model(embeddings)\n",
    "            else:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['binary_label'].to(device)\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            outputs = one_hot_encode(labels)\n",
    "            predicted_probs = torch.sigmoid(outputs)\n",
    "            predicted_labels.extend(predicted_probs.cpu().numpy() > 0.4)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return true_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "92ba995c-20da-4c39-bc8d-b7a50459531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_labels, predicted_labels = eval_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ac2872ec-f23b-4226-9fd5-b9ce22b8dcb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score, f1_score, recall_score, precision_score\n\u001b[0;32m----> 3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[43mtrue_labels\u001b[49m, predicted_labels)\n\u001b[1;32m      4\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(true_labels, predicted_labels,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# Assuming multilabel\u001b[39;00m\n\u001b[1;32m      5\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(true_labels, predicted_labels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m,zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Assuming multilabel\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels,average='weighted', zero_division=True) # Assuming multilabel\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted',zero_division=True)  # Assuming multilabel\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted',zero_division=True)  # Assuming multilabel\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6b5115d3-a4e9-4aa2-bd4c-e658da94bd5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrue_labels\u001b[49m, predicted_labels,\n\u001b[1;32m      3\u001b[0m     target_names\u001b[38;5;241m=\u001b[39mlabel_columns,\n\u001b[1;32m      4\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# label_names is a list of class names\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(report)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "report = classification_report(\n",
    "    true_labels, predicted_labels,\n",
    "    target_names=label_columns,\n",
    "    zero_division=True)  # label_names is a list of class names\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc459ae1-dd98-45ac-97f8-8f618d9137d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
