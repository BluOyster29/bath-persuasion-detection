{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'loader_map' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 61\u001b[0m\n\u001b[1;32m     57\u001b[0m         experiment_confs\u001b[38;5;241m.\u001b[39mappend(loader_map)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m experiment_confs\n\u001b[0;32m---> 61\u001b[0m experiments \u001b[38;5;241m=\u001b[39m \u001b[43mgen_loader_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_root_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_root_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 56\u001b[0m, in \u001b[0;36mgen_loader_map\u001b[0;34m(train_root_folder, test_root_folder)\u001b[0m\n\u001b[1;32m     54\u001b[0m test_paths \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(test_root_folder)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(train_root_folder):\n\u001b[0;32m---> 56\u001b[0m     loader_map \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     experiment_confs\u001b[38;5;241m.\u001b[39mappend(loader_map)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m experiment_confs\n",
      "Cell \u001b[0;32mIn[16], line 48\u001b[0m, in \u001b[0;36mupdate_metadata\u001b[0;34m(train_path, test_paths)\u001b[0m\n\u001b[1;32m     45\u001b[0m         loader_map \u001b[38;5;241m=\u001b[39m update_dic(trainloader_path, test_loader_path, root)\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader_map\u001b[49m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'loader_map' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os \n",
    "import pickle \n",
    "\n",
    "train_root_folder = '/Users/rt853/repos/UoB/bath-persuasion-detection/data/processed/dataloaders/training'\n",
    "test_root_folder = '/Users/rt853/repos/UoB/bath-persuasion-detection/data/processed/dataloaders/testing'\n",
    "\n",
    "def init_loader_map():\n",
    "    loader_map = {\n",
    "        'dataloaders' : {\n",
    "            'training_path' : None,\n",
    "            'testing_path' : None},\n",
    "        'model' : None,\n",
    "        'embeddings' : None,\n",
    "        'sampled' : None,\n",
    "        'drop_labels' : None\n",
    "        }\n",
    "    return loader_map\n",
    "\n",
    "def update_dic(trainloader_path, test_loader_path, root):\n",
    "    \n",
    "    loader_map = init_loader_map()\n",
    "    loader_map['dataloaders']['training_path'] = trainloader_path\n",
    "    loader_map['dataloaders']['testing_path'] = test_loader_path\n",
    "    \n",
    "    if root.split('_')[0] == 'TODBERT':\n",
    "        loader_map['embeddings'] = 'TODBERT/TOD-BERT-JNT-V1'\n",
    "        loader_map['model'] = 'todbert'\n",
    "    else:\n",
    "        loader_map['embeddings'] = root.split('_')[0]\n",
    "        loader_map['model'] = loader_map['embeddings'].split('-')[0]\n",
    "    loader_map['sampled'] = root.split('_')[2]\n",
    "    loader_map['drop_labels'] = root.split('_')[5]\n",
    "    return loader_map\n",
    "\n",
    "def update_metadata(train_path, test_paths):\n",
    "    \n",
    "    for i in test_paths:\n",
    "        root = train_path.split('_')[1:]\n",
    "        root = '_'.join(root)[:-4]\n",
    "    \n",
    "        if re.search(root, i):\n",
    "            trainloader_path = f'{train_root_folder}{train_path}'\n",
    "            test_loader_path = f'{test_root_folder}{i}'\n",
    "            loader_map = update_dic(trainloader_path, test_loader_path, root)\n",
    "            break\n",
    "    \n",
    "    return loader_map\n",
    "    \n",
    "def gen_loader_map(train_root_folder, test_root_folder):\n",
    "    \n",
    "\n",
    "    experiment_confs = []\n",
    "    test_paths = os.listdir(test_root_folder)\n",
    "    for path in os.listdir(train_root_folder):\n",
    "        loader_map = update_metadata(path, test_paths)\n",
    "        experiment_confs.append(loader_map)\n",
    "        \n",
    "    return experiment_confs\n",
    "\n",
    "experiments = gen_loader_map(train_root_folder, test_root_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np \n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "class PersuasionStrategyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_token_len\n",
    "            ):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "        self.LABEL_COLUMNS = data.columns.tolist()[1:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        data_row = self.data.iloc[index]\n",
    "        comment_text = data_row.text\n",
    "        labels = data_row[self.LABEL_COLUMNS]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            )\n",
    "\n",
    "        return dict(\n",
    "            comment_text=comment_text,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
    "            labels=torch.FloatTensor(labels)\n",
    "        )\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    BERT-based classifier model.\n",
    "\n",
    "    Args:\n",
    "        bert_model (str): The pre-trained BERT model to use.\n",
    "        num_labels (int): The number of output labels.\n",
    "\n",
    "    Attributes:\n",
    "        bert (BertModel): The BERT model.\n",
    "        dropout (nn.Dropout): Dropout layer for regularization.\n",
    "        classifier (nn.Linear): Linear layer for classification.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, bert_model, num_labels):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.name = name\n",
    "        self.bert = AutoModel.from_pretrained(bert_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Forward pass of the BERT classifier.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): The input token IDs.\n",
    "            attention_mask (torch.Tensor): The attention mask.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The logits for each class.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.name == 'bert':\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "            pooled_output = outputs.pooler_output\n",
    "\n",
    "        elif self.name == 'distilbert':\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask)\n",
    "            pooled_output = outputs.last_hidden_state[:, 0, :]\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Invalid model name\")\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_model(\n",
    "        model, training_dataloader, num_epochs, device, optimizer, criterion):\n",
    "\n",
    "    avg_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(range(num_epochs), desc='Average Epoch Loss: ') as t:\n",
    "        for e in range(num_epochs):\n",
    "            epoch_loss = []\n",
    "\n",
    "            with tqdm(range(len(training_dataloader)), desc='Loss: 0') as t2:\n",
    "                for b, batch in enumerate(training_dataloader):\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    input_ids = batch['input_ids'].to(device)\n",
    "                    attention_mask = batch['attention_mask'].to(device)\n",
    "                    labels = batch['labels'].to(device)\n",
    "                    outputs = model(input_ids, attention_mask)\n",
    "\n",
    "                    loss = criterion(outputs, labels.float())\n",
    "                    epoch_loss.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    avg_epoch_loss = round(sum(epoch_loss)/len(epoch_loss), 4)\n",
    "                    description = f'Epoch: {e} | '\n",
    "                    description += f'Batch {b} | '\n",
    "                    description += f'Average Loss: {avg_epoch_loss}'\n",
    "\n",
    "                    t2.set_description(description)\n",
    "                    t2.update()\n",
    "\n",
    "            t.set_description(\n",
    "                f'Average Epoch Loss: \\\n",
    "                    {round(sum(epoch_loss)/len(epoch_loss), 4)}')\n",
    "            t.update()\n",
    "\n",
    "    return avg_loss, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import dill as pickle \n",
    "\n",
    "def init_model(config, label_columns):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()  # Binary cross-entropy loss for multilabel classification\n",
    "\n",
    "    model = BertClassifier('distilbert', config.get('embeddings'), len(label_columns))\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "    return model, device, criterion, optimizer\n",
    "\n",
    "def fetch_loaders(config):\n",
    "    with open(config['dataloaders']['training_path'], 'rb') as f:\n",
    "        train_loader = pickle.load(f)\n",
    "    \n",
    "    with open(config['dataloaders']['testing_path'], 'rb') as f:\n",
    "        test_loader = pickle.load(f)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, eval_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model on the evaluation data.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to evaluate.\n",
    "        eval_loader (torch.utils.data.DataLoader): The data loader for\n",
    "        the evaluation data.\n",
    "        device (torch.device): The device to run the evaluation on.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the true labels and predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(eval_loader):\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "            predicted_probs = torch.sigmoid(outputs)\n",
    "            predicted_labels.extend(predicted_probs.cpu().numpy() > 0.4)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def gen_stats(true_labels, predicted_labels, labels=None):\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(\n",
    "        true_labels, predicted_labels, average='weighted', zero_division=True)\n",
    "    recall = recall_score(\n",
    "        true_labels, predicted_labels, average='weighted', zero_division=True)\n",
    "    f1 = f1_score(\n",
    "        true_labels, predicted_labels, average='weighted', zero_division=True)\n",
    "    report = classification_report(\n",
    "        true_labels, predicted_labels, target_names=labels, zero_division=True)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall, 'f1': f1,\n",
    "        'report': report\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def gen_result_path(config, root_folder):\n",
    "    \n",
    "    path = f'{root_folder}{config[\"model\"]}'\n",
    "    path += f'_{config[\"sampled\"]}_{config[\"drop_labels\"]}.json'\n",
    "    return path\n",
    "    \n",
    "def save_results(results, config, root_folder):\n",
    "    file_path = gen_result_path(config, root_folder)\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexperiments\u001b[49m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEmbeddings : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSampled : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDrop Labels : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiments' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for e in experiments:\n",
    "    \n",
    "    print(f'Model : {e.get(\"model\")} \\nEmbeddings : {e.get(\"embeddings\")}\\nSampled : {e.get(\"sampled\")}\\nDrop Labels : {e.get(\"drop_labels\")}\\n')\n",
    "    print('---' * 20 + '\\n')\n",
    "    if e.get('model') == 'todbert':\n",
    "        continue \n",
    "    training_dataloader, testing_dataloader = fetch_loaders(e)\n",
    "    model, device, num_epochs, criterion, optimizer = init_model(e, training_dataloader.dataset.LABEL_COLUMNS)\n",
    "    trained_model = train_model(model, training_dataloader, num_epochs, device, optimizer, criterion)\n",
    "    true_labels, predicted_labels = eval_model(trained_model, testing_dataloader, device)\n",
    "    stats = gen_stats(true_labels, predicted_labels, testing_dataloader.dataset.LABEL_COLUMNS)\n",
    "    save_results(stats, e, './')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
